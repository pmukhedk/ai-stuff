{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d9533b-089d-4e3f-97fb-551f6eeaca05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.51.1-py3-none-any.whl (383 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib/python3.9/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/app-root/lib/python3.9/site-packages (from openai) (4.66.5)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.1/326.1 kB\u001b[0m \u001b[31m245.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/app-root/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/app-root/lib/python3.9/site-packages (from openai) (1.10.18)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m220.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m221.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /opt/app-root/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m242.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64de6583-543a-4780-87cd-a2e88be6dc17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/app-root/lib/python3.9/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.8)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/app-root/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.12.2)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81585cf7-7dee-4a46-949b-02178e2f4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Few-Shot Prompting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530cabf5-2c3f-4d31-ac27-be1ebb1ad271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played at Dolphin Stadium in Miami, Florida.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize an OpenAI client with the specified base URL and API key.\n",
    "# The `base_url` is a custom endpoint, this base url points to the model that is running on openshift ai platform\n",
    "client = OpenAI(\n",
    "    base_url='http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama'  # Required, but unused in this specific setup\n",
    ")\n",
    "\n",
    "# Create a chat completion request to interact with the AI model.\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2:latest\",  # Specify the model to use (in this case, \"llama2:latest\").\n",
    "  messages=[\n",
    "    # Define a conversation flow with roles for each message.\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the behavior of the assistant.\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},  # User's question.\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},  # Assistant's response.\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}  # User's follow-up question.\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Print the content of the assistant's response to the last user question.\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684e6bc-3f30-4964-9188-1d8fe391be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single-Shot Prompting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35694ece-f0e9-4f9c-bc3d-aba1f8529532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a quick one:\n",
      "\n",
      "Why don't scientists trust atoms? Because they make up everything! 😁\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2:latest\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"tell me a quick joke\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26e283-7701-45b9-ac04-d424a424a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Math Problem Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeb39e8c-53e5-4a7f-a625-642c7ea6f457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you solve the equation 12 * 8 + 15.\n",
      "\n",
      "To perform the multiplication, we need to multiply 12 by 8, which gives us 96. Then, we add 15 to that result:\n",
      "\n",
      "96 + 15 = 111\n",
      "\n",
      "So, the solution to the equation is 111.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2:latest\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a math expert.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you solve 12 * 8 + 15?\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6a5dc-c176-446a-b792-af1cc08145a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate a Sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b664e3bc-10fd-4d32-b5e0-0ccdb53772bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ओह लायकिने कैसे हैं (Oh lakeene kaisa hai)\n",
      "\n",
      "Explanation:\n",
      "\n",
      "* हेLLO (hello) is translated to \"ओह\" (oh) in Hindi.\n",
      "* लायकिने (laikine) is the Hindi word for \"how\", and it means \"कैसे\" (kaise) in English, so we translated it as \"कैसे हैं\" (kaise hai).\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2:latest\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a language translator.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate 'Hello, how are you?' into Hindi.\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061156ea-0566-4a8e-b4d3-289d65d2e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Summarization Example using llama2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb52d0d5-bdad-4822-b554-98baeb42b4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sure! Here is a summary of the text you provided:\n",
      "\n",
      "Artificial Intelligence (AI) is a field of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. AI encompasses various technologies such as machine learning, deep learning, natural language processing, and robotics. It is applied in different industries for more efficiency and solving complex problems. While AI has made significant progress over the past few decades, ethical concerns and ensuring transparency and fairness are still challenges that need to be addressed.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama2:latest\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert at summarizing long texts.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summarize the following text: 'Artificial Intelligence (AI) is a field of computer science that focuses on creating intelligent machines capable of performing tasks that typically require human intelligence. AI encompasses a variety of technologies, including machine learning, deep learning, natural language processing, and robotics. It is used in various industries, such as healthcare, finance, and transportation, to improve efficiency and solve complex problems. Over the past few decades, AI has made significant progress, but there are still challenges to overcome, such as ethical concerns and ensuring that AI systems are transparent and fair.'\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181e3fd-f720-4a52-ab89-0e8a5ae62983",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Summarization Example using Mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc275fd-90ab-4c82-a85d-c717dc369f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a branch of computer science concerned with building intelligent machines capable of performing tasks traditionally requiring human intelligence. AI incorporates multiple technologies, including machine learning, deep learning, natural language processing, and robotics. It is applied in numerous sectors, such as healthcare, finance, and transportation, to enhance productivity and tackle complex issues.\n",
      "\n",
      "Progress in AI has been substantial over the years; however, there are still hurdles to address, like ethical concerns and ensuring transparency and fairness in AI systems.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://ollama-route-ollama.apps.cluster-dr48f.dr48f.sandbox2558.opentlc.com/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"instructlab/granite-7b-lab:latest\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert at summarizing long texts.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summarize the following text: 'Artificial Intelligence (AI) is a field of computer science that focuses on creating intelligent machines capable of performing tasks that typically require human intelligence. AI encompasses a variety of technologies, including machine learning, deep learning, natural language processing, and robotics. It is used in various industries, such as healthcare, finance, and transportation, to improve efficiency and solve complex problems. Over the past few decades, AI has made significant progress, but there are still challenges to overcome, such as ethical concerns and ensuring that AI systems are transparent and fair.'\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
